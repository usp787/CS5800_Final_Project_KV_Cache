{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMi10Bw7pi7WKI58IYJWnFG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/usp787/CS5800_Final_Project_KV_Cache/blob/Code/kv_cache_code_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "StphgGPM3y-U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import psutil\n",
        "import os\n",
        "from typing import List, Dict, Tuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set style for better-looking plots\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)"
      ],
      "metadata": {
        "id": "Vm-H0DmnEYr0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURATION - Easy to Edit\n",
        "\n",
        "CONFIG = {\n",
        "    # Experiment parameters\n",
        "    'output_lengths': [10, 50, 100, 250, 500],  # Token lengths to test\n",
        "    'trials_per_length': 3,                      # Number of trials per length\n",
        "    'initial_prompt': \"The future of artificial intelligence\",  # Starting prompt\n",
        "\n",
        "    # Generation parameters\n",
        "    'temperature': 0.7,\n",
        "    'top_k': 50,\n",
        "    'do_sample': True,\n",
        "\n",
        "    # Model\n",
        "    'model_name': 'distilgpt2'\n",
        "}"
      ],
      "metadata": {
        "id": "vQ2Zr06BEbrd"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}